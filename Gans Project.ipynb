{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f79c2a22904f61d3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"google/MusicCaps\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T10:13:28.928073300Z",
     "start_time": "2024-04-15T10:13:01.419787Z"
    }
   },
   "id": "28915c87e3dfca42"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['ytid', 'start_s', 'end_s', 'audioset_positive_labels', 'aspect_list', 'caption', 'author_id', 'is_balanced_subset', 'is_audioset_eval'],\n        num_rows: 5521\n    })\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T10:13:28.967789600Z",
     "start_time": "2024-04-15T10:13:28.925070400Z"
    }
   },
   "id": "f097e86edd0391c0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_df = dataset['train'].to_pandas()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T10:13:29.043197800Z",
     "start_time": "2024-04-15T10:13:28.956219Z"
    }
   },
   "id": "7a67b83516b175a0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "             ytid  start_s  end_s  \\\n0     -0Gj8-vB1q4       30     40   \n1     -0SdAVK79lg       30     40   \n2     -0vPFx-wRRI       30     40   \n3     -0xzrMun0Rs       30     40   \n4     -1LrH01Ei1w       30     40   \n...           ...      ...    ...   \n5516  zw5dkiklbhE       15     25   \n5517  zwfo7wnXdjs       30     40   \n5518  zx_vcwOsDO4       50     60   \n5519  zyXa2tdBTGc       30     40   \n5520  zzNdwF40ID8       70     80   \n\n                               audioset_positive_labels  \\\n0                          /m/0140xf,/m/02cjck,/m/04rlf   \n1     /m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...   \n2                                   /m/025_jnm,/m/04rlf   \n3                                    /m/01g90h,/m/04rlf   \n4                                   /m/02p0sh1,/m/04rlf   \n...                                                 ...   \n5516                                /m/01sm1g,/m/0l14md   \n5517                      /m/02p0sh1,/m/04rlf,/m/06j64v   \n5518  /m/01glhc,/m/02sgy,/m/0342h,/m/03lty,/m/04rlf,...   \n5519                                /m/04rlf,/t/dd00034   \n5520                                  /m/04rlf,/m/0790c   \n\n                                            aspect_list  \\\n0     ['low quality', 'sustained strings melody', 's...   \n1     ['guitar song', 'piano backing', 'simple percu...   \n2     ['amateur recording', 'finger snipping', 'male...   \n3     ['backing track', 'jazzy', 'digital drums', 'p...   \n4     ['rubab instrument', 'repetitive melody on dif...   \n...                                                 ...   \n5516  ['amateur recording', 'percussion', 'wooden bo...   \n5517  ['instrumental music', 'arabic music', 'genera...   \n5518  ['instrumental', 'no voice', 'electric guitar'...   \n5519  ['instrumental music', 'gospel music', 'strong...   \n5520  ['glitch', 'noise', 'instrumental', 'electroni...   \n\n                                                caption  author_id  \\\n0     The low quality recording features a ballad so...          4   \n1     This song features an electric guitar as the m...          0   \n2     a male voice is singing a melody with changing...          6   \n3     This song contains digital drums playing a sim...          6   \n4     This song features a rubber instrument being p...          0   \n...                                                 ...        ...   \n5516  This audio contains someone playing a wooden b...          6   \n5517  The song is an instrumental. The song is mediu...          1   \n5518  The rock music is purely instrumental and feat...          2   \n5519  The song is an instrumental. The song is slow ...          1   \n5520  This is a glitch music piece. There is a synth...          9   \n\n      is_balanced_subset  is_audioset_eval  \n0                  False              True  \n1                  False             False  \n2                  False              True  \n3                  False              True  \n4                  False             False  \n...                  ...               ...  \n5516               False             False  \n5517                True              True  \n5518                True              True  \n5519               False             False  \n5520                True              True  \n\n[5521 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ytid</th>\n      <th>start_s</th>\n      <th>end_s</th>\n      <th>audioset_positive_labels</th>\n      <th>aspect_list</th>\n      <th>caption</th>\n      <th>author_id</th>\n      <th>is_balanced_subset</th>\n      <th>is_audioset_eval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0Gj8-vB1q4</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/0140xf,/m/02cjck,/m/04rlf</td>\n      <td>['low quality', 'sustained strings melody', 's...</td>\n      <td>The low quality recording features a ballad so...</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0SdAVK79lg</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...</td>\n      <td>['guitar song', 'piano backing', 'simple percu...</td>\n      <td>This song features an electric guitar as the m...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0vPFx-wRRI</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/025_jnm,/m/04rlf</td>\n      <td>['amateur recording', 'finger snipping', 'male...</td>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0xzrMun0Rs</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/01g90h,/m/04rlf</td>\n      <td>['backing track', 'jazzy', 'digital drums', 'p...</td>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1LrH01Ei1w</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/02p0sh1,/m/04rlf</td>\n      <td>['rubab instrument', 'repetitive melody on dif...</td>\n      <td>This song features a rubber instrument being p...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5516</th>\n      <td>zw5dkiklbhE</td>\n      <td>15</td>\n      <td>25</td>\n      <td>/m/01sm1g,/m/0l14md</td>\n      <td>['amateur recording', 'percussion', 'wooden bo...</td>\n      <td>This audio contains someone playing a wooden b...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5517</th>\n      <td>zwfo7wnXdjs</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/02p0sh1,/m/04rlf,/m/06j64v</td>\n      <td>['instrumental music', 'arabic music', 'genera...</td>\n      <td>The song is an instrumental. The song is mediu...</td>\n      <td>1</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5518</th>\n      <td>zx_vcwOsDO4</td>\n      <td>50</td>\n      <td>60</td>\n      <td>/m/01glhc,/m/02sgy,/m/0342h,/m/03lty,/m/04rlf,...</td>\n      <td>['instrumental', 'no voice', 'electric guitar'...</td>\n      <td>The rock music is purely instrumental and feat...</td>\n      <td>2</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5519</th>\n      <td>zyXa2tdBTGc</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/04rlf,/t/dd00034</td>\n      <td>['instrumental music', 'gospel music', 'strong...</td>\n      <td>The song is an instrumental. The song is slow ...</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5520</th>\n      <td>zzNdwF40ID8</td>\n      <td>70</td>\n      <td>80</td>\n      <td>/m/04rlf,/m/0790c</td>\n      <td>['glitch', 'noise', 'instrumental', 'electroni...</td>\n      <td>This is a glitch music piece. There is a synth...</td>\n      <td>9</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5521 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T10:13:29.131568800Z",
     "start_time": "2024-04-15T10:13:29.036728Z"
    }
   },
   "id": "28d30a66e5e05473"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0       The low quality recording features a ballad so...\n1       This song features an electric guitar as the m...\n2       a male voice is singing a melody with changing...\n3       This song contains digital drums playing a sim...\n4       This song features a rubber instrument being p...\n                              ...                        \n5516    This audio contains someone playing a wooden b...\n5517    The song is an instrumental. The song is mediu...\n5518    The rock music is purely instrumental and feat...\n5519    The song is an instrumental. The song is slow ...\n5520    This is a glitch music piece. There is a synth...\nName: caption, Length: 5521, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['caption']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:07.104007500Z",
     "start_time": "2024-04-03T15:02:07.060757900Z"
    }
   },
   "id": "a0ca4d22e0ea17cf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing the WAV files\n",
    "wav_folder = 'music_data'  # Update this with your actual folder path\n",
    "\n",
    "# Function to get the WAV file path based on YouTube ID\n",
    "def get_wav_path(ytid):\n",
    "    return os.path.join(wav_folder, f\"{ytid}.wav\")\n",
    "\n",
    "# Create a list to store tuples of captions and WAV file paths\n",
    "caption_wav_list = []\n",
    "\n",
    "# Iterate through the rows of the original DataFrame\n",
    "for index, row in train_df.iterrows():\n",
    "    # Get the YouTube ID and caption\n",
    "    ytid = row['ytid']\n",
    "    caption = row['caption']\n",
    "    \n",
    "    # Get the WAV file path\n",
    "    wav_path = get_wav_path(ytid)\n",
    "    \n",
    "    # Append the caption and WAV file path to the list\n",
    "    caption_wav_list.append((caption, wav_path))\n",
    "\n",
    "# Create a new DataFrame from the list\n",
    "caption_wav_df = pd.DataFrame(caption_wav_list, columns=['caption', 'wav_path'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:07.366766800Z",
     "start_time": "2024-04-03T15:02:07.088957500Z"
    }
   },
   "id": "db72d86c60b29b4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                caption  \\\n0     The low quality recording features a ballad so...   \n1     This song features an electric guitar as the m...   \n2     a male voice is singing a melody with changing...   \n3     This song contains digital drums playing a sim...   \n4     This song features a rubber instrument being p...   \n...                                                 ...   \n5516  This audio contains someone playing a wooden b...   \n5517  The song is an instrumental. The song is mediu...   \n5518  The rock music is purely instrumental and feat...   \n5519  The song is an instrumental. The song is slow ...   \n5520  This is a glitch music piece. There is a synth...   \n\n                        wav_path  \n0     music_data\\-0Gj8-vB1q4.wav  \n1     music_data\\-0SdAVK79lg.wav  \n2     music_data\\-0vPFx-wRRI.wav  \n3     music_data\\-0xzrMun0Rs.wav  \n4     music_data\\-1LrH01Ei1w.wav  \n...                          ...  \n5516  music_data\\zw5dkiklbhE.wav  \n5517  music_data\\zwfo7wnXdjs.wav  \n5518  music_data\\zx_vcwOsDO4.wav  \n5519  music_data\\zyXa2tdBTGc.wav  \n5520  music_data\\zzNdwF40ID8.wav  \n\n[5521 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>music_data\\-0Gj8-vB1q4.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>music_data\\-0SdAVK79lg.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>music_data\\-0vPFx-wRRI.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>music_data\\-0xzrMun0Rs.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>music_data\\-1LrH01Ei1w.wav</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5516</th>\n      <td>This audio contains someone playing a wooden b...</td>\n      <td>music_data\\zw5dkiklbhE.wav</td>\n    </tr>\n    <tr>\n      <th>5517</th>\n      <td>The song is an instrumental. The song is mediu...</td>\n      <td>music_data\\zwfo7wnXdjs.wav</td>\n    </tr>\n    <tr>\n      <th>5518</th>\n      <td>The rock music is purely instrumental and feat...</td>\n      <td>music_data\\zx_vcwOsDO4.wav</td>\n    </tr>\n    <tr>\n      <th>5519</th>\n      <td>The song is an instrumental. The song is slow ...</td>\n      <td>music_data\\zyXa2tdBTGc.wav</td>\n    </tr>\n    <tr>\n      <th>5520</th>\n      <td>This is a glitch music piece. There is a synth...</td>\n      <td>music_data\\zzNdwF40ID8.wav</td>\n    </tr>\n  </tbody>\n</table>\n<p>5521 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:07.380814600Z",
     "start_time": "2024-04-03T15:02:07.367767500Z"
    }
   },
   "id": "46c51484214d5a82"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "caption_wav_df = caption_wav_df[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:07.424357Z",
     "start_time": "2024-04-03T15:02:07.383817800Z"
    }
   },
   "id": "f3ef21432676c7a6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                      wav_path  \n0   music_data\\-0Gj8-vB1q4.wav  \n1   music_data\\-0SdAVK79lg.wav  \n2   music_data\\-0vPFx-wRRI.wav  \n3   music_data\\-0xzrMun0Rs.wav  \n4   music_data\\-1LrH01Ei1w.wav  \n..                         ...  \n95  music_data\\-taO6N-rxv4.wav  \n96  music_data\\-tmY1GEH3_Y.wav  \n97  music_data\\-tpq_bzSKes.wav  \n98  music_data\\-uaTK8sa5Ms.wav  \n99  music_data\\-v5hgCh3M2w.wav  \n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>music_data\\-0Gj8-vB1q4.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>music_data\\-0SdAVK79lg.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>music_data\\-0vPFx-wRRI.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>music_data\\-0xzrMun0Rs.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>music_data\\-1LrH01Ei1w.wav</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>music_data\\-taO6N-rxv4.wav</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>music_data\\-tmY1GEH3_Y.wav</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>music_data\\-tpq_bzSKes.wav</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>music_data\\-uaTK8sa5Ms.wav</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>music_data\\-v5hgCh3M2w.wav</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:07.472667500Z",
     "start_time": "2024-04-03T15:02:07.396845200Z"
    }
   },
   "id": "e14f76872abf9ef1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Medhansh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Medhansh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Medhansh\\AppData\\Local\\Temp\\ipykernel_21272\\478400242.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  caption_wav_df['processed_caption'] = caption_wav_df['caption'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get list of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply text preprocessing to captions in the DataFrame\n",
    "caption_wav_df['processed_caption'] = caption_wav_df['caption'].apply(preprocess_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:10.908086200Z",
     "start_time": "2024-04-03T15:02:07.415738500Z"
    }
   },
   "id": "34196f9aae07891b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 866\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit tokenizer on the processed captions\n",
    "tokenizer.fit_on_texts(caption_wav_df['processed_caption'])\n",
    "\n",
    "# Convert tokens to sequences of word indices\n",
    "sequences = tokenizer.texts_to_sequences(caption_wav_df['processed_caption'])\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_caption_length = 58 # Example maximum length of caption sequence\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_caption_length, padding='post')\n",
    "\n",
    "# Inspect vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) +1 # Add 1 for padding token\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:16.869838400Z",
     "start_time": "2024-04-03T15:02:10.902068200Z"
    }
   },
   "id": "6381afa02ce8ddcb"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sequence: [ 15  10   4   7 160   2  96  84  64  85  22   3  76  24  18  11   6 111\n",
      " 216  51 112 113  65 337 338   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inspect example sequence\n",
    "print(\"Example sequence:\", padded_sequences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:16.946943400Z",
     "start_time": "2024-04-03T15:02:16.870851Z"
    }
   },
   "id": "cf4386dbf8a39427"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(58,)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "padded_sequences[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:16.948940600Z",
     "start_time": "2024-04-03T15:02:16.895737600Z"
    }
   },
   "id": "f6599d6a24cf0a59"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of processed captions: 58\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(caption) for caption in caption_wav_df['processed_caption'])\n",
    "print(\"Maximum length of processed captions:\", max_length)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:16.950941500Z",
     "start_time": "2024-04-03T15:02:16.916240500Z"
    }
   },
   "id": "8428e68d0eba6e8d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['low',\n 'quality',\n 'recording',\n 'features',\n 'ballad',\n 'song',\n 'contains',\n 'sustained',\n 'strings',\n 'mellow',\n 'piano',\n 'melody',\n 'soft',\n 'female',\n 'vocal',\n 'singing',\n 'sounds',\n 'sad',\n 'soulful',\n 'like',\n 'something',\n 'would',\n 'hear',\n 'sunday',\n 'services']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df['processed_caption'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:16.997464Z",
     "start_time": "2024-04-03T15:02:16.937911700Z"
    }
   },
   "id": "c598d9f79d307f22"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                      wav_path  \\\n0   music_data\\-0Gj8-vB1q4.wav   \n1   music_data\\-0SdAVK79lg.wav   \n2   music_data\\-0vPFx-wRRI.wav   \n3   music_data\\-0xzrMun0Rs.wav   \n4   music_data\\-1LrH01Ei1w.wav   \n..                         ...   \n95  music_data\\-taO6N-rxv4.wav   \n96  music_data\\-tmY1GEH3_Y.wav   \n97  music_data\\-tpq_bzSKes.wav   \n98  music_data\\-uaTK8sa5Ms.wav   \n99  music_data\\-v5hgCh3M2w.wav   \n\n                                    processed_caption  \n0   [low, quality, recording, features, ballad, so...  \n1   [song, features, electric, guitar, main, instr...  \n2   [male, voice, singing, melody, changing, tempo...  \n3   [song, contains, digital, drums, playing, simp...  \n4   [song, features, rubber, instrument, played, s...  \n..                                                ...  \n95  [rock, music, piece, playing, background, tuto...  \n96  [low, quality, recording, features, pop, song,...  \n97  [composition, contains, upright, bass, playing...  \n98  [acoustic, drum, set, playing, 16th, note, rhy...  \n99  [soft, rock, song, features, passionate, femal...  \n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n      <th>processed_caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>music_data\\-0Gj8-vB1q4.wav</td>\n      <td>[low, quality, recording, features, ballad, so...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>music_data\\-0SdAVK79lg.wav</td>\n      <td>[song, features, electric, guitar, main, instr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>music_data\\-0vPFx-wRRI.wav</td>\n      <td>[male, voice, singing, melody, changing, tempo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>music_data\\-0xzrMun0Rs.wav</td>\n      <td>[song, contains, digital, drums, playing, simp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>music_data\\-1LrH01Ei1w.wav</td>\n      <td>[song, features, rubber, instrument, played, s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>music_data\\-taO6N-rxv4.wav</td>\n      <td>[rock, music, piece, playing, background, tuto...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>music_data\\-tmY1GEH3_Y.wav</td>\n      <td>[low, quality, recording, features, pop, song,...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>music_data\\-tpq_bzSKes.wav</td>\n      <td>[composition, contains, upright, bass, playing...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>music_data\\-uaTK8sa5Ms.wav</td>\n      <td>[acoustic, drum, set, playing, 16th, note, rhy...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>music_data\\-v5hgCh3M2w.wav</td>\n      <td>[soft, rock, song, features, passionate, femal...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:17.104955300Z",
     "start_time": "2024-04-03T15:02:16.957965Z"
    }
   },
   "id": "d29cafbe55bce6fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tejas ka code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78eea039e228ab60"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# \n",
    "# # Convert processed captions to text strings\n",
    "# captions_text = caption_wav_df['processed_caption'].apply(lambda x: ' '.join(x))\n",
    "# \n",
    "# # Initialize tokenizer\n",
    "# tokenizer = Tokenizer()\n",
    "# \n",
    "# # Fit tokenizer on captions text\n",
    "# tokenizer.fit_on_texts(captions_text)\n",
    "# \n",
    "# # Convert text to sequences of integers\n",
    "# sequences = tokenizer.texts_to_sequences(captions_text)\n",
    "# \n",
    "# # Get maximum sequence length\n",
    "# max_seq_length = max(len(seq) for seq in sequences)\n",
    "# \n",
    "# # Pad sequences to ensure uniform length\n",
    "# padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "# \n",
    "# # Update processed captions in DataFrame with padded sequences\n",
    "# caption_wav_df['padded_caption'] = padded_sequences.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:17.107875500Z",
     "start_time": "2024-04-03T15:02:16.990519700Z"
    }
   },
   "id": "b70265987095c31a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# padded_sequences[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:17.107875500Z",
     "start_time": "2024-04-03T15:02:17.006524100Z"
    }
   },
   "id": "22cf05d7fb3516ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to convert WAV files to spectrograms and save images\n",
    "def convert_to_spectrogram(wav_path, specto_folder):\n",
    "    # Load the audio file\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {wav_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Compute the spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    db_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    \n",
    "    # Save the spectrogram image\n",
    "    specto_path = os.path.join(specto_folder, '-'+os.path.basename(wav_path).replace('.wav', '.png'))\n",
    "    plt.imsave(specto_path, db_spectrogram, cmap='viridis', format='png')\n",
    "    \n",
    "    return specto_path\n",
    "\n",
    "# Create a folder for spectrograms if it doesn't exist\n",
    "specto_folder = 'specto'\n",
    "if not os.path.exists(specto_folder):\n",
    "    os.makedirs(specto_folder)\n",
    "\n",
    "# Apply the function to each WAV file and store the paths\n",
    "caption_wav_df['specto_path'] = caption_wav_df['wav_path'].apply(lambda x: convert_to_spectrogram(x, specto_folder))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e60dd74c710775"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                      wav_path  \\\n0   music_data\\-0Gj8-vB1q4.wav   \n1   music_data\\-0SdAVK79lg.wav   \n2   music_data\\-0vPFx-wRRI.wav   \n3   music_data\\-0xzrMun0Rs.wav   \n4   music_data\\-1LrH01Ei1w.wav   \n..                         ...   \n95  music_data\\-taO6N-rxv4.wav   \n96  music_data\\-tmY1GEH3_Y.wav   \n97  music_data\\-tpq_bzSKes.wav   \n98  music_data\\-uaTK8sa5Ms.wav   \n99  music_data\\-v5hgCh3M2w.wav   \n\n                                    processed_caption  \n0   [low, quality, recording, features, ballad, so...  \n1   [song, features, electric, guitar, main, instr...  \n2   [male, voice, singing, melody, changing, tempo...  \n3   [song, contains, digital, drums, playing, simp...  \n4   [song, features, rubber, instrument, played, s...  \n..                                                ...  \n95  [rock, music, piece, playing, background, tuto...  \n96  [low, quality, recording, features, pop, song,...  \n97  [composition, contains, upright, bass, playing...  \n98  [acoustic, drum, set, playing, 16th, note, rhy...  \n99  [soft, rock, song, features, passionate, femal...  \n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n      <th>processed_caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>music_data\\-0Gj8-vB1q4.wav</td>\n      <td>[low, quality, recording, features, ballad, so...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>music_data\\-0SdAVK79lg.wav</td>\n      <td>[song, features, electric, guitar, main, instr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>music_data\\-0vPFx-wRRI.wav</td>\n      <td>[male, voice, singing, melody, changing, tempo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>music_data\\-0xzrMun0Rs.wav</td>\n      <td>[song, contains, digital, drums, playing, simp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>music_data\\-1LrH01Ei1w.wav</td>\n      <td>[song, features, rubber, instrument, played, s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>music_data\\-taO6N-rxv4.wav</td>\n      <td>[rock, music, piece, playing, background, tuto...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>music_data\\-tmY1GEH3_Y.wav</td>\n      <td>[low, quality, recording, features, pop, song,...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>music_data\\-tpq_bzSKes.wav</td>\n      <td>[composition, contains, upright, bass, playing...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>music_data\\-uaTK8sa5Ms.wav</td>\n      <td>[acoustic, drum, set, playing, 16th, note, rhy...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>music_data\\-v5hgCh3M2w.wav</td>\n      <td>[soft, rock, song, features, passionate, femal...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:17.109875500Z",
     "start_time": "2024-04-03T15:02:17.031668700Z"
    }
   },
   "id": "d5db430e81c6ff8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image_path = \"D:\\PycharmProjects\\Gans Project\\specto\\--0Gj8-vB1q4.png\"  # Replace with the path to your image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Get the size of the image\n",
    "image_size = image.size  # Returns a tuple (width, height)\n",
    "\n",
    "# Print the size of the image\n",
    "print(\"Image size (width x height):\", image_size)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5fb9b8a01913bd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "def build_generator(max_caption_length, spectrogram_shape):\n",
    "    # Caption input\n",
    "    caption_input = Input(shape=(max_caption_length,))\n",
    "    \n",
    "    # Reshape the input for LSTM\n",
    "    caption_input_reshaped = Reshape((max_caption_length, 1))(caption_input)\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm_units = 128\n",
    "    lstm_output = LSTM(units=lstm_units)(caption_input_reshaped)\n",
    "    lstm_output = Dense(units=128, activation='relu')(lstm_output)  # Add a dense layer to match shape with CNN output\n",
    "\n",
    "    # Spectrogram input\n",
    "    spectrogram_input = Input(shape=spectrogram_shape)\n",
    "\n",
    "    # Reshape the spectrogram input to add batch dimension\n",
    "    spectrogram_input_reshaped = Reshape((spectrogram_shape[0], spectrogram_shape[1], 1))(spectrogram_input)\n",
    "\n",
    "    # CNN layer\n",
    "    cnn_output = Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu')(spectrogram_input_reshaped)\n",
    "    cnn_output = MaxPooling2D(pool_size=(2, 2))(cnn_output)\n",
    "    cnn_output = Flatten()(cnn_output)\n",
    "    cnn_output = Dense(units=128, activation='relu')(cnn_output)\n",
    "\n",
    "    # Concatenate LSTM and CNN outputs\n",
    "    concatenated = Concatenate()([lstm_output, cnn_output])\n",
    "\n",
    "    # Additional layers\n",
    "    x = Dense(units=256, activation='relu')(concatenated)\n",
    "    x = Dense(units=512, activation='relu')(x)\n",
    "    x = Dense(units=1024, activation='relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(units=spectrogram_shape[0] * spectrogram_shape[1], activation='tanh')(x)\n",
    "    output_reshaped = Reshape(spectrogram_shape)(output)\n",
    "\n",
    "    # Model\n",
    "    generator = Model(inputs=[caption_input, spectrogram_input], outputs=output_reshaped)\n",
    "\n",
    "    return generator\n",
    "\n",
    "# Define the maximum caption length and spectrogram shape\n",
    "max_caption_length = 58  # Assuming this value based on the provided data\n",
    "spectrogram_shape = (861, 128)  # Shape of your spectrogram images\n",
    "\n",
    "# Build the generator model\n",
    "generator = build_generator(max_caption_length, spectrogram_shape)\n",
    "\n",
    "# Display the model summary\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34cabc90a66bc269"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Conv2D, BatchNormalization, ReLU, Conv2DTranspose, Reshape, Add, Activation, LSTM, Dense, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def build_generator(max_caption_length, spectrogram_shape):\n",
    "    # Caption input\n",
    "    caption_input = Input(shape=(max_caption_length,))\n",
    "    \n",
    "    # LSTM layer\n",
    "    lstm_units = 128\n",
    "    lstm_output = LSTM(units=lstm_units, return_sequences=True)(Reshape((-1, 1))(caption_input))\n",
    "    lstm_output = LSTM(units=lstm_units)(lstm_output)\n",
    "    \n",
    "    # Spectrogram input\n",
    "    spectrogram_input = Input(shape=spectrogram_shape)\n",
    "    \n",
    "    # Spectrogram processing layers (Convolutional layers)\n",
    "    conv1d_filters = 16\n",
    "    conv_kernel_size = 3\n",
    "    x = Conv1D(filters=conv1d_filters, kernel_size=conv_kernel_size, padding='same')(spectrogram_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Reshape spectrogram to match Conv2DTranspose input shape\n",
    "    x = Reshape((spectrogram_shape[0], 1, conv1d_filters))(x)\n",
    "    \n",
    "    # Upsampling layers\n",
    "    upsampling_factor = 8\n",
    "    x = Conv2DTranspose(filters=conv1d_filters, kernel_size=(1, 4), strides=(1, upsampling_factor), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual stack\n",
    "    residual_blocks = 8\n",
    "    for _ in range(residual_blocks):\n",
    "        residual_output = residual_block(x, conv1d_filters)\n",
    "        x = Add()([x, residual_output])\n",
    "    \n",
    "    # Upsampling layers\n",
    "    x = Conv2DTranspose(filters=1, kernel_size=(1, 4), strides=(1, 2), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual stack\n",
    "    for _ in range(residual_blocks):\n",
    "        residual_output = residual_block(x, 1)\n",
    "        x = Add()([x, residual_output])\n",
    "    \n",
    "    # Convolutional layer\n",
    "    x = Conv2D(filters=1, kernel_size=(1, 7), padding='same')(x)\n",
    "    \n",
    "    # Flatten and reshape\n",
    "    x = Reshape((-1,))(x)\n",
    "    \n",
    "    # Model output\n",
    "    generator_output = Activation('tanh')(x)\n",
    "    \n",
    "    # Concatenate LSTM output with Convolutional output\n",
    "    merged_output = Concatenate()([lstm_output, generator_output])\n",
    "    \n",
    "    # Final dense layer to output raw waveform\n",
    "    output_waveform = Dense(units=8000, activation='tanh')(merged_output)\n",
    "    \n",
    "    # Build model\n",
    "    generator = Model(inputs=[caption_input, spectrogram_input], outputs=output_waveform)\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def residual_block(input_tensor, filters):\n",
    "    x = Conv2D(filters=filters, kernel_size=(1, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(1, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# Example usage\n",
    "max_caption_length = 58\n",
    "spectrogram_shape = (861, 128)\n",
    "generator = build_generator(max_caption_length, spectrogram_shape)\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a94d1a42ed28f2d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, Conv2D, BatchNormalization, ReLU, Conv2DTranspose, Reshape, Add, Activation, LSTM, Dense, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def build_generator(max_caption_length, spectrogram_shape, output_waveform_size):\n",
    "    # Caption input\n",
    "    caption_input = Input(shape=(max_caption_length,))\n",
    "    \n",
    "    # LSTM layer\n",
    "    lstm_units = 64\n",
    "    lstm_output = LSTM(units=lstm_units, return_sequences=True)(Reshape((-1, 1))(caption_input))\n",
    "    lstm_output = LSTM(units=lstm_units)(lstm_output)\n",
    "    \n",
    "    # Spectrogram input\n",
    "    spectrogram_input = Input(shape=spectrogram_shape)\n",
    "    \n",
    "    # Spectrogram processing layers (Convolutional layers)\n",
    "    conv1d_filters = 4\n",
    "    conv_kernel_size = 3\n",
    "    x = Conv1D(filters=conv1d_filters, kernel_size=conv_kernel_size, padding='same')(spectrogram_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Reshape spectrogram to match Conv2DTranspose input shape\n",
    "    x = Reshape((spectrogram_shape[0], 1, conv1d_filters))(x)\n",
    "    \n",
    "    # Upsampling layers\n",
    "    upsampling_factor = 2\n",
    "    x = Conv2DTranspose(filters=conv1d_filters, kernel_size=(1, 4), strides=(1, upsampling_factor), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual stack\n",
    "    residual_blocks = 2\n",
    "    for _ in range(residual_blocks):\n",
    "        residual_output = residual_block(x, conv1d_filters)\n",
    "        x = Add()([x, residual_output])\n",
    "    \n",
    "    # Upsampling layers\n",
    "    x = Conv2DTranspose(filters=1, kernel_size=(1, 4), strides=(1, 2), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual stack\n",
    "    for _ in range(residual_blocks):\n",
    "        residual_output = residual_block(x, 1)\n",
    "        x = Add()([x, residual_output])\n",
    "    \n",
    "    # Convolutional layer\n",
    "    x = Conv2D(filters=1, kernel_size=(1, 7), padding='same')(x)\n",
    "    \n",
    "    # Flatten and reshape\n",
    "    x = Reshape((-1,))(x)\n",
    "    \n",
    "    # Model output\n",
    "    generator_output = Activation('tanh')(x)\n",
    "    \n",
    "    # Concatenate LSTM output with Convolutional output\n",
    "    merged_output = Concatenate()([lstm_output, generator_output])\n",
    "    \n",
    "    # Final dense layer to output raw waveform\n",
    "    output_waveform = Dense(units=output_waveform_size, activation='tanh')(merged_output)\n",
    "    \n",
    "    # Build model\n",
    "    generator = Model(inputs=[caption_input, spectrogram_input], outputs=output_waveform)\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def residual_block(input_tensor, filters):\n",
    "    x = Conv2D(filters=filters, kernel_size=(1, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(1, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# Example usage\n",
    "max_caption_length = 58\n",
    "spectrogram_shape = (861, 128)\n",
    "output_waveform_size = 441000  # For 10-second audio sampled at 44100 Hz\n",
    "generator = build_generator(max_caption_length, spectrogram_shape, output_waveform_size)\n",
    "generator.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90d31234c828b3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "def trim_audio(input_file, output_folder):\n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "\n",
    "    # Trim the audio to the desired segment (0 to 3 seconds)\n",
    "    start_time = 0\n",
    "    end_time = 3\n",
    "    start_index = int(start_time * sample_rate)\n",
    "    end_index = int(end_time * sample_rate)\n",
    "    trimmed_audio = audio_data[start_index:end_index]\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Save the trimmed audio to a new file\n",
    "    output_file = os.path.join(output_folder, os.path.basename(input_file))\n",
    "    sf.write(output_file, trimmed_audio, sample_rate)\n",
    "\n",
    "# Directory containing audio files\n",
    "input_folder = \"D:\\PycharmProjects\\Gans Project\\music_data\"\n",
    "\n",
    "# Directory to save trimmed audio files\n",
    "output_folder = \"D:\\PycharmProjects\\Gans Project\\Trimed\"\n",
    "\n",
    "# Iterate over audio files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        input_file = os.path.join(input_folder, filename)\n",
    "        # Trim the audio and save it to the output folder\n",
    "        trim_audio(input_file, output_folder)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27944237aa7e259f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def extract_features(input_file):\n",
    "    # Load the audio file\n",
    "    audio_data, _ = librosa.load(input_file, sr=None)\n",
    "\n",
    "    # Apply convolutional layer\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(audio_data.shape[0], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)  # Output layer, adjust units according to your task\n",
    "    ])\n",
    "\n",
    "    # Reshape audio data for input to the model\n",
    "    audio_data = audio_data.reshape(1, -1, 1)\n",
    "\n",
    "    # Extract features using the model\n",
    "    features = model.predict(audio_data)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Single audio file\n",
    "input_file = \"music_data\"\n",
    "\n",
    "# Extract features from the audio file\n",
    "features = extract_features(input_file)\n",
    "\n",
    "# Directory to save the extracted features\n",
    "output_folder = \"D:\\PycharmProjects\\Gans Project\\Trimed_!\"\n",
    "\n",
    "# Save the features to a file\n",
    "output_file = os.path.join(output_folder, os.path.basename(input_file).replace(\".wav\", \".npy\"))\n",
    "np.save(output_file, features)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6281860b7c2866e"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall librosa\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:11:11.773059400Z",
     "start_time": "2024-04-03T07:07:15.592169900Z"
    }
   },
   "id": "5c5248ab72d11226"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 861, 128)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 861, 6)       2310        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 861, 6)      24          ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 861, 6)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 861, 1, 6)    0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 861, 4, 6)   150         ['reshape_1[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 861, 4, 6)    0           ['conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 861, 4, 6)    114         ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 861, 4, 6)   24          ['conv2d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 861, 4, 6)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 861, 4, 6)    114         ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 861, 4, 6)    0           ['re_lu_1[0][0]',                \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 861, 4, 6)    114         ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 861, 4, 6)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 861, 4, 6)    114         ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 861, 4, 6)    0           ['add[0][0]',                    \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 861, 4, 6)    114         ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 861, 4, 6)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 861, 4, 6)    114         ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 861, 4, 6)    0           ['add_1[0][0]',                  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 861, 4, 6)    114         ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 861, 4, 6)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 861, 4, 6)    114         ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 861, 4, 6)   24          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 861, 4, 6)    0           ['add_2[0][0]',                  \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 861, 8, 1)   25          ['add_3[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 861, 8, 1)    0           ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 861, 8, 1)    4           ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 861, 8, 1)   4           ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 861, 8, 1)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 861, 8, 1)    4           ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 861, 8, 1)   4           ['conv2d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 861, 8, 1)    0           ['re_lu_6[0][0]',                \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 861, 8, 1)    4           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 861, 8, 1)   4           ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 861, 8, 1)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 861, 8, 1)    4           ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 861, 8, 1)   4           ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 861, 8, 1)    0           ['add_4[0][0]',                  \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 861, 8, 1)    4           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 861, 8, 1)   4           ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 861, 8, 1)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 861, 8, 1)    4           ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 861, 8, 1)   4           ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 861, 8, 1)    0           ['add_5[0][0]',                  \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 861, 8, 1)    4           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 861, 8, 1)   4           ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 861, 8, 1)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 861, 8, 1)    4           ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 861, 8, 1)   4           ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 861, 8, 1)    0           ['add_6[0][0]',                  \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 861, 8, 1)    8           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 6888)         0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 58)]         0           []                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 6888)         0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,685\n",
      "Trainable params: 3,561\n",
      "Non-trainable params: 124\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, Conv2D, BatchNormalization, ReLU, Conv2DTranspose, Reshape, Add, Activation, LSTM, Dense, Concatenate, Lambda, Flatten\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def build_generator_segment(segment_length, max_caption_length, spectrogram_shape):\n",
    "    # Caption input\n",
    "    caption_input = Input(shape=(max_caption_length,))\n",
    "    \n",
    "    # LSTM layer\n",
    "    lstm_units = 128\n",
    "    lstm_output = LSTM(units=lstm_units, return_sequences=True)(Reshape((-1, 1))(caption_input))\n",
    "    lstm_output = LSTM(units=lstm_units)(lstm_output)\n",
    "    \n",
    "    # Spectrogram input\n",
    "    spectrogram_input = Input(shape=spectrogram_shape)\n",
    "    \n",
    "    # Spectrogram processing layers (Convolutional layers)\n",
    "    conv1d_filters = 6\n",
    "    conv_kernel_size = 3\n",
    "    x = Conv1D(filters=conv1d_filters, kernel_size=conv_kernel_size, padding='same')(spectrogram_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Reshape spectrogram to match Conv2DTranspose input shape\n",
    "    x = Reshape((spectrogram_shape[0], 1, conv1d_filters))(x)\n",
    "    \n",
    "    # Upsampling layers\n",
    "    upsampling_factor = 4\n",
    "    x = Conv2DTranspose(filters=conv1d_filters, kernel_size=(1, 4), strides=(1, upsampling_factor), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual stack\n",
    "    residual_blocks = 4\n",
    "    for _ in range(residual_blocks):\n",
    "        residual_output = residual_block(x, conv1d_filters)\n",
    "        x = Add()([x, residual_output])\n",
    "    \n",
    "    # Upsampling layers\n",
    "    x = Conv2DTranspose(filters=1, kernel_size=(1, 4), strides=(1, 2), padding='same')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual stack\n",
    "    for _ in range(residual_blocks):\n",
    "        residual_output = residual_block(x, 1)\n",
    "        x = Add()([x, residual_output])\n",
    "    \n",
    "    # Convolutional layer\n",
    "    x = Conv2D(filters=1, kernel_size=(1, 7), padding='same')(x)\n",
    "    \n",
    "    # Flatten and reshape\n",
    "    x = Reshape((-1,))(x)\n",
    "    \n",
    "    # Model output\n",
    "    generator_output = Activation('tanh')(x)\n",
    "    \n",
    "    # Reshape output into segments\n",
    "    num_segments = int(generator_output.shape[1]) // segment_length\n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        segment = Lambda(lambda x: x[:, i * segment_length: (i + 1) * segment_length])(generator_output)\n",
    "        segments.append(segment)\n",
    "    \n",
    "    if segments:\n",
    "        # Concatenate segments\n",
    "        concatenated_segments = Concatenate(axis=0)(segments)\n",
    "    else:\n",
    "        # If segments list is empty, return the generator output\n",
    "        concatenated_segments = generator_output\n",
    "    \n",
    "    # Model\n",
    "    generator_segment = Model(inputs=[caption_input, spectrogram_input], outputs=concatenated_segments)\n",
    "    \n",
    "    return generator_segment\n",
    "\n",
    "def residual_block(input_tensor, filters):\n",
    "    x = Conv2D(filters=filters, kernel_size=(1, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=filters, kernel_size=(1, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# Example usage\n",
    "segment_length = 20 * 44100  \n",
    "max_caption_length = 58\n",
    "spectrogram_shape = (861, 128)\n",
    "generator_segment = build_generator_segment(segment_length, max_caption_length, spectrogram_shape)\n",
    "generator_segment.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:02:37.359125800Z",
     "start_time": "2024-04-03T15:02:33.419392200Z"
    }
   },
   "id": "f98e97ec9e548ad4"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 882000, 1)]       0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 441000, 16)        96        \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 441000, 16)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7056000)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 7056001   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,056,097\n",
      "Trainable params: 7,056,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, LeakyReLU, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def build_discriminator(segment_length):\n",
    "    # Input for the generated or real audio segment\n",
    "    audio_input = Input(shape=(segment_length, 1))\n",
    "    \n",
    "    # Convolutional layers\n",
    "    x = Conv1D(filters=16, kernel_size=5, strides=2, padding='same')(audio_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Flatten layer\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Output layer\n",
    "    validity = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Discriminator model\n",
    "    discriminator = Model(inputs=audio_input, outputs=validity)\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "# Example usage\n",
    "segment_length = 20 * 44100  # Segment length in number of samples\n",
    "discriminator = build_discriminator(segment_length)\n",
    "discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:03:08.456756900Z",
     "start_time": "2024-04-03T15:03:08.390516500Z"
    }
   },
   "id": "5b8ad5aa515d0157"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 882000, 1)]       0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 441000, 8)         48        \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 441000, 8)         0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 220500, 16)        656       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 220500, 16)        0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 110250, 32)        2592      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 110250, 32)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3528000)           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3528001   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,531,297\n",
      "Trainable params: 3,531,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, LeakyReLU, Flatten, Dense\n",
    "\n",
    "def build_discriminator(segment_length):\n",
    "    # Input for the generated or real audio segment\n",
    "    audio_input = Input(shape=(segment_length, 1))\n",
    "    \n",
    "    # Convolutional layers\n",
    "    x = Conv1D(filters=8, kernel_size=5, strides=2, padding='same')(audio_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Additional Convolutional layer\n",
    "    x = Conv1D(filters=16, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Additional Convolutional layer\n",
    "    x = Conv1D(filters=32, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Flatten layer\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Output layer\n",
    "    validity = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Discriminator model\n",
    "    discriminator = Model(inputs=audio_input, outputs=validity)\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "# Example usage\n",
    "segment_length = 20 * 44100  # Segment length in number of samples\n",
    "discriminator = build_discriminator(segment_length)\n",
    "discriminator.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:07:19.187118300Z",
     "start_time": "2024-04-03T15:07:19.055962Z"
    }
   },
   "id": "e2504d340aed87c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a5bcab51981adc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.9 (tensorflow)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
